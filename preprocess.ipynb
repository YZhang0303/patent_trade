{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4275769, 40)\n",
      "(600437, 40)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_csv(\"中国专利转让数据库1998-2024年.csv\")\n",
    "print(df.shape)\n",
    "df = df.filter(pl.col(\"申请日\") < \"2010-01-01\")\n",
    "print(df.shape)\n",
    "\n",
    "# 只保留选中的列\n",
    "df = df.select([\n",
    "    \"申请号\",\n",
    "    \"历史法律状态\"\n",
    "])\n",
    "print(f\"筛选列后的形状: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81dd3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_csv(\"中国专利转让数据库1998-2024年.csv\")\n",
    "df = df.select([\n",
    "    \"申请号\",\n",
    "    \"IPC分类号\",\n",
    "    \"IPC主分类号\",\n",
    "])\n",
    "df.write_parquet('ipc信息.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3bfaec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载Polars原生优化版本\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import time\n",
    "\n",
    "def expand_legal_status_native(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    使用Polars原生操作的高性能版本\n",
    "    \"\"\"\n",
    "    print(f\"处理 {len(df):,} 行数据...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 使用Polars原生字符串操作和向量化处理\n",
    "    result = (\n",
    "        df.with_row_index()\n",
    "        # 按#分割法律状态记录\n",
    "        .with_columns(\n",
    "            pl.col(\"历史法律状态\")\n",
    "            .str.split(\"#\")\n",
    "            .alias(\"status_blocks\")\n",
    "        )\n",
    "        # 展开每个状态块\n",
    "        .explode(\"status_blocks\")\n",
    "        # 过滤空值\n",
    "        .filter(pl.col(\"status_blocks\").is_not_null() & (pl.col(\"status_blocks\").str.len_chars() > 0))\n",
    "        # 提取法律状态公告日\n",
    "        .with_columns([\n",
    "            pl.col(\"status_blocks\")\n",
    "            .str.extract(r\"法律状态公告日：([^；\\n]+)\")\n",
    "            .alias(\"法律状态公告日\"),\n",
    "            \n",
    "            # 提取法律状态\n",
    "            pl.col(\"status_blocks\")\n",
    "            .str.extract(r\"法律状态：([^；\\n]+)\")\n",
    "            .alias(\"当前法律状态\"),\n",
    "            \n",
    "            # 提取描述信息\n",
    "            pl.col(\"status_blocks\")\n",
    "            .str.extract(r\"描述信息：([^；\\n]+)\")\n",
    "            .alias(\"状态描述信息\"),\n",
    "            \n",
    "            # 保留原始数据\n",
    "            pl.col(\"历史法律状态\").alias(\"原始历史法律状态\")\n",
    "        ])\n",
    "        # 重新排列列顺序\n",
    "        .select([\n",
    "            \"法律状态公告日\",\n",
    "            \"当前法律状态\", \n",
    "            \"状态描述信息\",\n",
    "            \"申请号\",\n",
    "            \"原始历史法律状态\"\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"处理完成！原始记录: {len(df):,}, 扩展后记录: {len(result):,}\")\n",
    "    print(f\"总耗时: {total_time:.2f} 秒\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def expand_legal_status_alternative(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    替代方案：使用map_elements但批量处理\n",
    "    \"\"\"\n",
    "    print(f\"处理 {len(df):,} 行数据...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    def parse_status_batch(status_text):\n",
    "        \"\"\"批量解析单个状态字符串\"\"\"\n",
    "        if not status_text or status_text == \"\":\n",
    "            return [{\"法律状态公告日\": None, \"当前法律状态\": None, \"状态描述信息\": None}]\n",
    "        \n",
    "        blocks = [block.strip() for block in str(status_text).split('#') if block.strip()]\n",
    "        if not blocks:\n",
    "            return [{\"法律状态公告日\": None, \"当前法律状态\": None, \"状态描述信息\": None}]\n",
    "        \n",
    "        results = []\n",
    "        for block in blocks:\n",
    "            result = {\"法律状态公告日\": None, \"当前法律状态\": None, \"状态描述信息\": None}\n",
    "            \n",
    "            lines = block.split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if '法律状态公告日：' in line:\n",
    "                    result[\"法律状态公告日\"] = line.split('法律状态公告日：', 1)[1].split('；')[0].strip()\n",
    "                elif '法律状态：' in line:\n",
    "                    result[\"当前法律状态\"] = line.split('法律状态：', 1)[1].split('；')[0].strip()\n",
    "                elif '描述信息：' in line:\n",
    "                    result[\"状态描述信息\"] = line.split('描述信息：', 1)[1].split('；')[0].strip()\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # 使用map_elements进行向量化处理\n",
    "    result = (\n",
    "        df.with_row_index()\n",
    "        .with_columns(\n",
    "            pl.col(\"历史法律状态\")\n",
    "            .map_elements(parse_status_batch, return_dtype=pl.List(pl.Struct({\n",
    "                \"法律状态公告日\": pl.Utf8,\n",
    "                \"当前法律状态\": pl.Utf8, \n",
    "                \"状态描述信息\": pl.Utf8\n",
    "            })))\n",
    "            .alias(\"parsed_status\")\n",
    "        )\n",
    "        .explode(\"parsed_status\")\n",
    "        .unnest(\"parsed_status\")\n",
    "        .with_columns(pl.col(\"历史法律状态\").alias(\"原始历史法律状态\"))\n",
    "        .select([\n",
    "            \"法律状态公告日\",\n",
    "            \"当前法律状态\",\n",
    "            \"状态描述信息\", \n",
    "            \"申请号\",\n",
    "            \"原始历史法律状态\"\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"处理完成！原始记录: {len(df):,}, 扩展后记录: {len(result):,}\")\n",
    "    print(f\"总耗时: {total_time:.2f} 秒\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"已加载Polars原生优化版本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21377e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 600,437 行数据...\n",
      "处理完成！原始记录: 600,437, 扩展后记录: 3,116,810\n",
      "总耗时: 3.96 秒\n"
     ]
    }
   ],
   "source": [
    "expanded_df = expand_legal_status_native(df)\n",
    "# 使用Polars原生操作版本（推荐）\n",
    "\n",
    "\n",
    "# 如果上面的版本有问题，可以尝试替代方案\n",
    "# expanded_df = expand_legal_status_alternative(df)\n",
    "\n",
    "# expanded_df = expanded_df.unique()\n",
    "# expanded_df.write_parquet(\"expanded_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df = expanded_df.unique()\n",
    "expanded_df[\"当前法律状态\"].value_counts().write_csv(\"当前法律状态.csv\")\n",
    "expanded_df.write_parquet(\"expanded_df2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0aed26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wytx8dkfbbg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载优化版本函数\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "def expand_legal_status_optimized(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    优化版本：利用Polars并行特性和分块处理\n",
    "    \"\"\"\n",
    "    print(f\"处理 {len(df):,} 行数据...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 优化策略1: 使用更高效的字符串操作\n",
    "    # 避免复杂正则表达式，使用简单字符串分割\n",
    "    result = (\n",
    "        df.with_row_index()\n",
    "        # 预过滤空值和无效数据\n",
    "        .filter(\n",
    "            pl.col(\"历史法律状态\").is_not_null() & \n",
    "            (pl.col(\"历史法律状态\").str.len_chars() > 10)\n",
    "        )\n",
    "        # 使用更高效的字符串分割\n",
    "        .with_columns(\n",
    "            pl.col(\"历史法律状态\")\n",
    "            .str.replace_all(r\"\\s+\", \" \")  # 标准化空白字符\n",
    "            .str.split(\"#\")\n",
    "            .alias(\"status_blocks\")\n",
    "        )\n",
    "        # 展开状态块\n",
    "        .explode(\"status_blocks\")\n",
    "        # 过滤空块\n",
    "        .filter(\n",
    "            pl.col(\"status_blocks\").is_not_null() & \n",
    "            (pl.col(\"status_blocks\").str.len_chars() > 5)\n",
    "        )\n",
    "        # 并行提取字段 - 避免复杂正则，使用简单字符串操作\n",
    "        .with_columns([\n",
    "            # 提取公告日 - 使用字符串分割而非正则\n",
    "            pl.col(\"status_blocks\")\n",
    "            .str.split(\"法律状态公告日：\").list.get(1, null_on_oob=True)\n",
    "            .str.split(\"；\").list.get(0, null_on_oob=True)\n",
    "            .str.strip_chars()\n",
    "            .alias(\"法律状态公告日\"),\n",
    "            \n",
    "            # 提取法律状态\n",
    "            pl.col(\"status_blocks\")\n",
    "            .str.split(\"法律状态：\").list.get(1, null_on_oob=True)\n",
    "            .str.split(\"；\").list.get(0, null_on_oob=True) \n",
    "            .str.strip_chars()\n",
    "            .alias(\"当前法律状态\"),\n",
    "            \n",
    "            # 提取描述信息\n",
    "            pl.col(\"status_blocks\")\n",
    "            .str.split(\"描述信息：\").list.get(1, null_on_oob=True)\n",
    "            .str.split(\"；\").list.get(0, null_on_oob=True)\n",
    "            .str.strip_chars() \n",
    "            .alias(\"状态描述信息\"),\n",
    "            \n",
    "            pl.col(\"历史法律状态\").alias(\"原始历史法律状态\")\n",
    "        ])\n",
    "        # 过滤有效记录\n",
    "        .filter(\n",
    "            pl.col(\"法律状态公告日\").is_not_null() |\n",
    "            pl.col(\"当前法律状态\").is_not_null() |\n",
    "            pl.col(\"状态描述信息\").is_not_null()\n",
    "        )\n",
    "        # 选择最终列\n",
    "        .select([\n",
    "            \"法律状态公告日\",\n",
    "            \"当前法律状态\", \n",
    "            \"状态描述信息\",\n",
    "            \"申请号\",\n",
    "            \"原始历史法律状态\"\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"优化版本处理完成！原始记录: {len(df):,}, 扩展后记录: {len(result):,}\")\n",
    "    print(f\"总耗时: {total_time:.2f} 秒\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def process_chunk(chunk_data):\n",
    "    \"\"\"处理单个数据块的函数\"\"\"\n",
    "    chunk_df, chunk_id = chunk_data\n",
    "    print(f\"处理块 {chunk_id}, 大小: {len(chunk_df):,}\")\n",
    "    return expand_legal_status_optimized(chunk_df)\n",
    "\n",
    "def expand_legal_status_parallel(df: pl.DataFrame, n_chunks: int = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    并行分块处理版本\n",
    "    \"\"\"\n",
    "    if n_chunks is None:\n",
    "        n_chunks = max(1, mp.cpu_count() - 1)  # 保留一个核心\n",
    "    \n",
    "    print(f\"使用 {n_chunks} 个进程进行并行处理\")\n",
    "    print(f\"处理 {len(df):,} 行数据...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 计算每块大小\n",
    "    chunk_size = len(df) // n_chunks\n",
    "    if chunk_size == 0:\n",
    "        return expand_legal_status_optimized(df)\n",
    "    \n",
    "    # 分割数据\n",
    "    chunks = []\n",
    "    for i in range(n_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        if i == n_chunks - 1:  # 最后一块包含剩余所有数据\n",
    "            end_idx = len(df)\n",
    "        else:\n",
    "            end_idx = (i + 1) * chunk_size\n",
    "        \n",
    "        chunk = df.slice(start_idx, end_idx - start_idx)\n",
    "        chunks.append((chunk, i + 1))\n",
    "    \n",
    "    # 并行处理\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=n_chunks) as executor:\n",
    "        future_to_chunk = {executor.submit(process_chunk, chunk): chunk[1] \n",
    "                          for chunk in chunks}\n",
    "        \n",
    "        for future in as_completed(future_to_chunk):\n",
    "            chunk_id = future_to_chunk[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                print(f\"块 {chunk_id} 处理完成\")\n",
    "            except Exception as exc:\n",
    "                print(f\"块 {chunk_id} 处理失败: {exc}\")\n",
    "    \n",
    "    # 合并结果\n",
    "    print(\"合并处理结果...\")\n",
    "    final_result = pl.concat(results)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"并行处理完成！原始记录: {len(df):,}, 扩展后记录: {len(final_result):,}\")\n",
    "    print(f\"总耗时: {total_time:.2f} 秒\")\n",
    "    print(f\"相比原版本预计提升: ~{24.36/total_time:.1f}x\")\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "print(\"已加载优化版本函数\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4lqizxnvlah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 性能对比测试 ===\n",
      "系统CPU核心数: 20\n",
      "可用于并行的核心数: 19\n",
      "\n",
      "测试样本大小: 10,000 行\n",
      "\n",
      "--- 测试优化版本（单线程）---\n",
      "处理 10,000 行数据...\n",
      "优化版本处理完成！原始记录: 10,000, 扩展后记录: 41,561\n",
      "总耗时: 0.09 秒\n",
      "\n",
      "--- 测试并行版本 ---\n",
      "并行版本需要在Python脚本中运行，Jupyter环境下可能有多进程限制\n",
      "\n",
      "=== 优化建议 ===\n",
      "1. 字符串分割替代正则表达式 - 性能提升显著\n",
      "2. 预过滤无效数据 - 减少处理量\n",
      "3. 并行分块处理 - 充分利用多核CPU\n",
      "4. 内存优化 - 避免不必要的数据复制\n"
     ]
    }
   ],
   "source": [
    "# 性能测试和对比\n",
    "print(\"=== 性能对比测试 ===\")\n",
    "print(f\"系统CPU核心数: {mp.cpu_count()}\")\n",
    "print(f\"可用于并行的核心数: {mp.cpu_count() - 1}\")\n",
    "\n",
    "# 使用小样本先测试优化版本\n",
    "test_sample = df.sample(n=10000, seed=42)\n",
    "print(f\"\\n测试样本大小: {len(test_sample):,} 行\")\n",
    "\n",
    "# 测试优化版本（单线程）\n",
    "print(\"\\n--- 测试优化版本（单线程）---\")\n",
    "optimized_result = expand_legal_status_optimized(test_sample)\n",
    "\n",
    "# 测试并行版本\n",
    "print(\"\\n--- 测试并行版本 ---\")\n",
    "if __name__ == '__main__':  # 避免在Jupyter中的多进程问题\n",
    "    # 在实际使用时取消注释下面的行\n",
    "    # parallel_result = expand_legal_status_parallel(test_sample, n_chunks=4)\n",
    "    print(\"并行版本需要在Python脚本中运行，Jupyter环境下可能有多进程限制\")\n",
    "\n",
    "print(\"\\n=== 优化建议 ===\")\n",
    "print(\"1. 字符串分割替代正则表达式 - 性能提升显著\")\n",
    "print(\"2. 预过滤无效数据 - 减少处理量\")\n",
    "print(\"3. 并行分块处理 - 充分利用多核CPU\")\n",
    "print(\"4. 内存优化 - 避免不必要的数据复制\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x7st4ou903o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 使用优化版本处理完整数据集 ===\n",
      "处理 4,275,769 行数据...\n"
     ]
    }
   ],
   "source": [
    "# 应用优化版本处理完整数据集\n",
    "print(\"=== 使用优化版本处理完整数据集 ===\")\n",
    "\n",
    "# 使用优化版本替代原来的方法\n",
    "expanded_df_optimized = expand_legal_status_optimized(df)\n",
    "\n",
    "# 去重并保存\n",
    "expanded_df_optimized = expanded_df_optimized.unique()\n",
    "print(f\"去重后记录数: {len(expanded_df_optimized):,}\")\n",
    "\n",
    "# 保存优化版本结果\n",
    "expanded_df_optimized.write_parquet(\"expanded_df_optimized.parquet\")\n",
    "print(\"优化版本结果已保存至 expanded_df_optimized.parquet\")\n",
    "\n",
    "# 数据质量检查\n",
    "print(\"\\n=== 数据质量检查 ===\")\n",
    "print(\"非空值统计:\")\n",
    "for col in [\"法律状态公告日\", \"当前法律状态\", \"状态描述信息\"]:\n",
    "    non_null_count = expanded_df_optimized.filter(pl.col(col).is_not_null()).height\n",
    "    print(f\"  {col}: {non_null_count:,} ({non_null_count/len(expanded_df_optimized)*100:.1f}%)\")\n",
    "\n",
    "# 显示样本数据\n",
    "print(\"\\n前5条处理结果:\")\n",
    "print(expanded_df_optimized.head().to_pandas())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
